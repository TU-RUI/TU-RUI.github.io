---
title: 两阶段聚合解决Flink数据倾斜问题
date: 2022-06-20 11:17:17.018
updated: 2022-06-20 11:42:54.616
img_path: /assets/img/upload/
categories: 
- 技术类
tags: 
- Flink
- 数据倾斜
---

# 一. 问题背景
热榜实时计算热词ctr的flink任务偶尔会收到告警提示作业健康度低，消费数据能力有所下降，调大CPU配额并未解决且导致CPU利用率低。后而观察到Flink任务在执行过程中数据倾斜比较严重，数据倾斜会导致Flink任务整体性能比预期差很多，因此决定在继续调整CPU配额之前，先把数据倾斜的问题解决一下。
![image-f691a709e8f9473c880c8f0113be0b63](image-f691a709e8f9473c880c8f0113be0b63.png)
![image-9e2527c9c6b24c85b7e6dee6148ccb17](image-9e2527c9c6b24c85b7e6dee6148ccb17.png)

# 二. 问题分析
热榜的Flink任务消费客户端上传的埋点数据，每10分钟统计一次不同热词的点击量和曝光量数据，先根据keyword(热词)将DataStream转换成KeyedStream(Flink SQL中的groupBy操作，api中的keyBy操作)，再实现自定义聚合函数，以每个热词为维度累计统计曝光量和点击量，10分钟统计一次进行输出。
![image-6fb96421ecba4a6f845ce3843afd97a3](image-6fb96421ecba4a6f845ce3843afd97a3.png)

&nbsp; &nbsp; 数据倾斜的发生原理参考：[Spark性能优化指南——高级篇](https://tech.meituan.com/2016/05/12/spark-tuning-pro.html)。在本案例中，数据倾斜发生在根据热词keyBy后把不同的热词发送到不同的slot中进行累计计算的时候。由于不同热榜热度差异可能比较大，会导致每个slot中数据量差异太大，产生数据倾斜。文章同时给出了几种解决数据倾斜的方案，在本案例中，数据倾斜发生在keyby后的聚合操作，不涉及join类的操作，适合用两阶段聚合的方案解决。两阶段聚合的解决思路是把一个根据key聚合的操作分成两阶段进行：
&nbsp; &nbsp; 第一次是局部聚合，先给每个keyword都加一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据的key，执行一次聚合操作，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。
&nbsp; &nbsp; 第二次是全局聚合，将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次聚合操作，就可以得到最终结果了，比如(hello, 4)。将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。
![image-3ee788f478f142829242fa832a5020b5](image-3ee788f478f142829242fa832a5020b5.png)

# 三. 解决步骤	
### 1、添加随机后缀
原来的计算流程：
```
//合并
DataStream<EventModel> eventStream = showStream.union(clickStream);

//窗口计算,写入计算结果
DataStream<InsightCtrMessageInfo> resultStream = eventStream
      //根据keyword分不同窗口计算
      .keyBy(v -> v.getKeyWord())
      //定义10分钟大小的翻转窗口
      .window(TumblingProcessingTimeWindows.of(Time.minutes(10)))
      //窗口内元素的聚合函数
      .aggregate(new MyAggregateFunction());
```
这里需要先给key拼接一个随机数，有几点注意事项：
* 随机数放在前缀后缀无所谓，只要能让原来的一个热词变为多个热词，起到打散的效果就行
* 不要直接keyBy(model -> model.getKeyWord + ThreadLocalRandom.current().nextInt())，这样会给keySelector引入随机变量。应该在keyBy()前把随机数附上。详情见：[【Flink纠错】IllegalArgumentException: key group from 44 to 45 does not contain 4](https://blog.csdn.net/qq_26502245/article/details/113363931)
* 使用随机数打散时，可使用ThreadLocalRandom.current().nextInt(N)，这里需要注意N值的大小，N值太大了数据太散，预聚合效果不好，N太小，无法保证数据均匀，因此N值的选取需要综合考虑于聚合效果和数据打散效果考虑。原因是根据热词进行keyBy分流后，会根据<font color=red>key的hash%并行度</font>计算改元素分配到哪个task中，相同的热词具有相同的hash，一定分配到同一个task中；不同的热词虽然拥有不同的hash，但是仍可能分配到同一个task中去。
![image-0e2c991a34344c55a2e9b917f4d17ee9](image-0e2c991a34344c55a2e9b917f4d17ee9.png)

修改后计算流程：
```
//合并
DataStream<EventModel> eventStream = showStream.union(clickStream);

//窗口计算,写入计算结果
DataStream<InsightCtrMessageInfo> resultStream = eventStream
    //给热词key添加随机后缀，防止数据倾斜
    .map(model -> {
        model.setKeyWord(model.getKeyWord() + "@@" + ThreadLocalRandom.current().nextInt(PARTITION));
        return model;
    })
    //根据keyword分不同窗口计算
    .keyBy(v -> v.getKeyWord())
    //定义10分钟大小的翻转窗口
    .window(TumblingProcessingTimeWindows.of(Time.minutes(10)))
    //根据hash后的keyword预聚合一次
    .aggregate(new PreAggregateFunction())
    .name("preAggregateFunction")
    //去掉热词key的后缀
    .map(accModel -> {
      	String[] array = accModel.getKeyWord().split("@@");
      	accModel.setKeyWord(array[0]);
      	return accModel;
    })
    //以热词为key自行再实现一次聚合
    .keyBy(accModel -> accModel.getKeyWord())
    .process(new MyTotalCountProcessFunction())
    .name("keyedProcessFunction");

```

### 2、预聚合
给原数据的keyword添加后缀后，根据新的keyword分别计算一次10分钟内的累加值，PreAggregateFunction实现如下：
```
private static class PreAggregateFunction implements AggregateFunction<EventModel, AccModel, AccModel> {
    //创建累加器
    @Override
    public AccModel createAccumulator() {
      return new AccModel();
    }

    @Override
    public AccModel add(EventModel eventModel, AccModel accModel) {
      if (accModel.getKeyWord() == null) {
        accModel.setKeyWord(eventModel.getKeyWord());
      }
      if (StringUtils.isEmpty(accModel.getWordId())) {
        accModel.setWordId(eventModel.getWordId());
      }
      if (EventTypeEnum.CLICK == eventModel.getEventType()) {
        accModel.setClickCount(accModel.getClickCount() + 1);
      } else if (EventTypeEnum.SHOW == eventModel.getEventType()) {
        accModel.setShowCount(accModel.getShowCount() + 1);
      }
      long eventTime = eventModel.getEventTime();
      if (eventTime > accModel.getHighTime()) {
        accModel.setHighTime(eventTime);
        accModel.setHighEventModel(eventModel);
      }
      if (accModel.getLowTime() == 0 || eventTime < accModel.getLowTime()) {
        accModel.setLowTime(eventTime);
        accModel.setLowEventModel(eventModel);
      }
      return accModel;
    }

    @Override
    public AccModel merge(AccModel accModel1, AccModel accModel2) {
      accModel1.setClickCount(accModel1.getClickCount() + accModel2.getClickCount());
      accModel1.setShowCount(accModel1.getShowCount() + accModel2.getShowCount());
      return accModel1;
    }

    @Override
    public AccModel getResult(AccModel accModel) {
      return accModel;
    }
}
```

### 3、去掉随机后缀
我们最终想要的是不同热词的CTR数据，第一步根据热词+随机后缀进行了一次聚合，想要得到最终的数据，还需要去掉随机后缀再做一次聚合

### 4、二次聚合
MyTotalCountProcessFunction的实现如下：
```
private static class MyTotalCountProcessFunction extends KeyedProcessFunction<String, AccModel, InsightCtrMessageInfo> {
  //保存键控状态，每一个key保存一个最终的AccModel值
  ValueState<AccModel> accModelState;

  @Override
  public void open(Configuration parameters) {
    accModelState = getRuntimeContext().getState(new ValueStateDescriptor<>("accModelTotalCount", AccModel.class));
  }

  @Override
  public void processElement(AccModel curAccModel, Context context, Collector<InsightCtrMessageInfo> collector) throws Exception {
    //更新最终AccModel的值
    AccModel finalAccModel;
    if (accModelState.value() == null) {
      finalAccModel = curAccModel;
    } else {
      finalAccModel = accModelState.value();
      finalAccModel.setShowCount(finalAccModel.getShowCount() + curAccModel.getShowCount());
      finalAccModel.setClickCount(finalAccModel.getClickCount() + curAccModel.getClickCount());
    }
    accModelState.update(finalAccModel);
    //设置时间触发器，如果没有新元素进入，10秒后触发。
    context.timerService().registerProcessingTimeTimer(context.timestamp() + 10000);
  }

  @Override
  public void onTimer(long timestamp, OnTimerContext ctx, Collector<InsightCtrMessageInfo> out) throws Exception {
    //10秒内没有新元素进入，输出到下一个算子操作
    AccModel finalAccModel = accModelState.value();
    InsightCtrMessageInfo insightCtrMessageInfo = buildProtoMessage(finalAccModel);
    logger.info("ctr结果输出：{}, lowTime={}, highTime={}, AccModel={}", toJSON(insightCtrMessageInfo),
                InsightCommonUtils.formatDate(finalAccModel.getLowTime()),
                InsightCommonUtils.formatDate(finalAccModel.getHighTime()),
                toJSON(finalAccModel));
    out.collect(insightCtrMessageInfo);
    accModelState.clear();
  }
}
```

# 四. 最终效果
**修复前：不同TM对CPU资源占用不均**
![image-9b3f977e16ed485dbf230b462f638e8e](image-9b3f977e16ed485dbf230b462f638e8e.png)
**修复后：不同TM数据处理条数均匀，对CPU资源占用均匀**
![image-0f3cd0956b6c4fbdab9b1f5de0ede6fa](image-0f3cd0956b6c4fbdab9b1f5de0ede6fa.png)
![image-7a28c7fa8b584a59a181088a30360c68](image-7a28c7fa8b584a59a181088a30360c68.png)

---
参考资料：
[Flink官方文档](https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/)
[Spark性能优化指南——高级篇](https://tech.meituan.com/2016/05/12/spark-tuning-pro.html)
[用两阶段聚合法解决Flink keyBy()算子倾斜](https://blog.csdn.net/nazeniwaresakini/article/details/104220120)
[Flink中对keyBy的探究](https://blog.csdn.net/dinghua_xuexi/article/details/107733729)
[Flink零基础教程：并行度和数据重分布](https://zhuanlan.zhihu.com/p/99695563)
[flink keyby 在 subtask 中分配不均的研究](https://segmentfault.com/a/1190000037458131)
[Flink处理函数实战之三：KeyedProcessFunction类](https://blog.csdn.net/boling_cavalry/article/details/106299167)
[谈谈Flink DataStream流计算中的优化](https://bbs.huaweicloud.com/blogs/178415)

