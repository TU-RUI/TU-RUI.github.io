---
title: gRPC概念介绍
date: 2022-06-20 11:20:25.116 +0800
updated: 2022-07-01 11:34:47.544
categories: 
- 技术类
tags: 
- gRPC
- HTTP/2
---

### 背景
随着微服务的兴起，几乎每一个互联网公司都有一套自己的内部网络通讯框架，例如阿里使用的Dubbo，本人之前在美团使用的是MTThrift框架，基于原生的Thrift二次开发得来的，加入快手后，发现快手使用的是gRpc框架，这让我感到好奇，快手和美团两家公司体量差不多，同为Java技术栈，为何一家选择了Thrift，一家选择了gRpc？在进行技术方案选型的时候，分别都是如何考虑的呢？带着这些疑问，决定深入学习一下gRpc框架。

---

## gRPC简介
### 为什么需要gRPC
一开始，我们的服务大多都是单体服务，随着业务规模不和代码量的扩大，原来的单体服务不得不面临拆分，而由单体服务拆分成微服务带来的一个问题就是服务之间的网络通信数量不断增加，我们服务变微了，但是网络连接数却有点膨胀了。 
 
 ![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/42f83013340b327720f8ed5b21199b27.png) 

&emsp;&emsp;随着网络连接数量的膨胀，服务间通信技术也在不断的发展，早期各个语言自行实现服务间的调用，例如Java可以使用RMI+原生的序列化，但是它的缺点是只能开发纯Java的应用。
&emsp;&emsp;因此SOAP协议出现后，开始受到很多大公司的喜爱，SOAP在设计上使用了更为通用的HTTP通信协议，并且以XML作为传输载体能在不同语言间使用。早期微软，IBM就有使用
&emsp;&emsp;随着rest风格架构的兴起，为人们提供了更为简单，灵活的选择，并且学习成本更低，json传输体积更小，因此restful一度成为微服务的标准通信模式
&emsp;&emsp;而最近几年，软件系统开始对于性能和开发效率有更高的追求，进程间通信技术慢慢的转向了以二进制数据为载体的高性能网络通信协议，例如Thrift，gRPC，本文就从0到1地来介绍gRPC。

![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/9897468dad8ccdec01a5ab7b4d782e92.png)

### 什么是gRPC
gRPC是一个高性能、开源、功能丰富的RPC框架，最初由Google开发，现在是CNCF(Cloud Native Computing Foundation)的一部分，gRPC中的g在不同时期有不同的含义，例如good, green, glorious, gRPC, game, geeky等等，RPC即远程服务调用（Remote Procedure Calls），远程服务调用能够让我们像调用本地函数一样调用另一台计算机上的远程函数，同时不必显式编码网络调用细节，另外现在大部分RPC框架也支持消费端和服务端使用不同语言编写

![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/cfeb2f1e1eb20b21d5115167bd0666fd.png)

### 开发一个gRPC程序
我们以ProductInfo商品信息服务为例，简单看一下如何开发grpc客户端和服务器端程序
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/13c4fde95c4de4509790ebae73f28464.png)

&emsp;&emsp;第一步，要定义一个消费端和服务端的接口。接口至少需要包含消费端消费服务的方式，提供给远程调用的方法，调用方法使用的参数和消息格式，另外gRPC框架一般使用ProtocolBuffer作为接口定义语言(IDL)
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/9e2f6b9264b589ad8cd929f8bdd42eec.png)

&emsp;&emsp;第二步，生成服务端代码，实现服务端逻辑，服务端代码也叫骨架代码，骨架代码提供低层级的通信框架，简化服务器端逻辑，有两种方式能帮助我们生成骨架代码，一种是使用protoc工具，另一种是使用本语言的打包插件，例如Java语言可以使用maven插件来生成
>  使用protoc工具         
```   
brew install protobuf
protoc --proto_path=src/main/proto --java_out=target/generated-sources/protobuf/java src/main/proto/*.proto
protoc --plugin=protoc-gen-grpc-java=/Users/turui/workspace/turui-grpc/target/protoc-plugins/protoc-gen-grpc-java-1.35.0-osx-x86_64.exe --grpc-java_out=target/generated-sources/protobuf/grpc-java --proto_path=src/main/proto src/main/proto/*.proto
```
> 使用maven插件   
```   
1. 添加protobuf-java/grpc-all依赖
2. 添加protobuf-maven-plugin插件
3. 使用protoc/grpc-plugin插件生成服务器端代码
4. compile/compile-custom
注：root-pom里已整合了此插件
```

&emsp;&emsp;第三步，生成客户端代码，实现客户端逻辑。客户端代码也叫存根代码，生成方式和第二步一样，需要使用相同的proto文件生成
```
public static void main(String[] args) throws InterruptedException {
    ManagedChannel channel = ManagedChannelBuilder.forAddress("localhost", 50051)
            .usePlaintext()
            .build();
    ProductInfoGrpc.ProductInfoBlockingStub stub =
            ProductInfoGrpc.newBlockingStub(channel);
    ProductInfoOuterClass.ProductID productID = stub.addProduct(
            ProductInfoOuterClass.Product.newBuilder()
                    .setName("Samsung S10")
                    .setDescription("Samsung Galaxy")
                    .setPrice(700.0f)
                    .build());
    logger.info("Product ID: " + productID.getValue() + " added successfully.");
    ProductInfoOuterClass.Product product = stub.getProduct(productID);
    logger.info("Product: " + product.toString());
    channel.shutdown();
}
```
&emsp;&emsp;拥有了相同的服务定义生成的骨架和存根后，客户端和服务器端就可以进行基于HTTP/2的网络通信了

### gRPC VS REST
早期的微服务实现主要使用 REST 架构作为事实上的通信技术，gRPC相较于REST，拥有更快的网络协议，更小的消息体积，强类型等多种优点，这些也是gRPC出现后被越来越多的人所关注的主要原因
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/cbc4a15384612068c3202d2d5c9a20ac.png)
&emsp;&emsp;和其他所有技术一样，gRPC也有一定的劣势，例如： 
* 不适合对外部提供的服务。gRPC具有契约驱动的特点，不适合提供给外部客户端使用
* 不适合服务经常发生破坏性的变更。如果是经常有无法向前兼容的变更，需要重新生成代码，让开发变得复杂
* 生态系统相对较小。例如服务注册，服务治理方案等等，支持还比较初级，浏览器和移动客户端对于HTTP/2的支持还处于初级阶段

## gRPC底层原理
回顾进程间通信技术的发展历程，从RMI到SOAP到REST再到gRPC，我们可以看到在选择进程间通信技术时，<font color=red>编码方式</font>和<font color=red>网络通信协议</font>是最核心的两点，这一节来介绍grpc的编码方式和通信协议
### gRPC调用流程
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/d97d5a775565e29e2ff29917a56e9fbb.png)
RPC框架的调用流程基本都类似，客户端调用 -> 客户端构造消息 -> 网络传输 -> 服务端解析消息 -> 服务端本地调用 -> 返回接口。不同RPC框架之间的区别基本都在与消息编码方式和网络通信协议上面
### 消息编码方式
gRPC使用ProtocolBuffer作为消息的编码方式，我们以商品信息服务为例，看一下消息是怎么被编码的
```proto
syntax = "proto3";

package ecommerce;

service ProductInfo {
  rpc getProduct(ProductID) returns (Product);
}

message Product {
  string id = 1;
  string name = 2;
  string description = 3;
  float price = 4;
}

message ProductID {
  string value = 1;
}
```
```java
ProductInfoOuterClass.Product product = stub.getProduct(ProductID.newBuilder().setValue("15").build());
```

&emsp;&emsp;当客户端调用getProduct方法，传入value为15的productId时，这个消息会被编码，grpc服务的入参只能有一个参数，这个参数一般是一个复合类型，可以包含很多个字段，本例中，productId会被编码成由一个字段加一个0组成的消息，每个字段由标签和值组成。  
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/e2446d5247884226e5da73d7ed555102.png)

&emsp;&emsp;标签由字段索引和线路类型计算而来。字段索引就是我们定义proto时给字段赋的id，例如string value = 1，此例中字段索引就是1。线路类型类似于变量的类型，但是proto有自己的一套定义，见下图

![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/471fa532cad89a8b373edbd8c8419ea1.png)

&emsp;&emsp;标签值的计算公式为：标签值 =（字段索引 << 3）| 线路类型，因此本例中标签值= (0000 0001 <<  3) | 0000 0010 = ``0x0A``

&emsp;&emsp;变量的线路类型不同，值也有不同的编码方式，例如对于Varint类型，使用不固定字节数的方式编码，每个字节的末尾都标识一下后面还有没有值；对于32-bit、64-bit采用的是固定位数的方式编码；对于Length-delimited，使用基于长度分隔的方式编码，把数据的长度放在首字节处。本例中value的类型string，线路类型是Length-delimited，值是'15'，因此编码后的值为``02 31 35``  
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/185be89c03ab78b332ad2b231a67cdf6.png)

&emsp;&emsp;标签和值拼接在一起，最终需要传输的数据为十六进制的``0A 02 31 35``，与REST常用的json传输相比，ProtocolBuffer节省的网络开销是十分巨大的   
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/6c58d97760a9032140ccf8896a047865.png)


### 通信协议
gRPC的通讯协议是HTTP/2.0，一般RPC框架为了提升性能，都会直接基于TCP协议来开发，为什么gRPC没有用更底层的TCP协议而是选择HTTP/2.0协议呢？
#### HTTP/1.X的问题
学习HTTP/2.0之前，我们先看看大部分RPC框架不使用HTTP/1.X的原因。
* 不支持并发。HTTP/1.X 只支持一个请求一个应答，如果加载10张图片，需要发送10次请求，并且浏览器一般仅支持同时发6-8个请求，因此客户端往往需要使用多个连接才能实现并发和稍微缩短延迟。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/c893a6e1053b9c9f8044c8dde7e4ed19.png)
* 产生不必要的流量。HTTP/1.X 不会压缩请求和响应的请求头，从而导致产生大量不必要的网络流量；每次请求带上重复的header，这些人工可读的文本对于机器来说其实并不在意
* 带宽利用率低下。HTTP/1.X 不支持有效的资源优先级，容易产生队首阻塞，致使底层 TCP 连接的利用率低下

&emsp;&emsp;以上的这些原因会导致使用HTTP/1.X作为进程间通信协议效率低下，因此大部分RPC框架选择了绕开HTTP，直接基于TCP协议作为通信协议。
#### 二进制分帧层
HTTP/2.0在原有的HTTP/1.X协议中引入了一个<font color=red>二进制分帧层</font>。在二进制分帧层中，使用多种新的技术来重新封装HTTP请求的消息，避免上面的这些的问题。下面主要介绍HPACK，多路复用，数据优先级。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/bc43c6f6f092ed1599d9bda86ad6bcbc.png)

#### HPACK
我们在浏览器输入任意一个网址，发送的请求里都会带上一大堆请求头，这些重复的请求头，对于客户端和服务器来说都是一种巨大的浪费 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/bb561b034587597a2be0cf632f666e59.png)

&emsp;&emsp;为了解决这个问题，HTTP/2.0在二进制分帧层使用HPACK技术对请求头部进行了压缩，HPACK也叫头部压缩，主要压缩方式如下。
* 第一，将Header中高频使用的固定key-value编成一个静态表，每个header对应一个数组索引，例如用'2'表示'method: GET'，每次请求时只用传这个索引而不是冗长的文本
* 第二，Header中不固定的value，例如cookie、path等使用huffman进行编码，而不是明文传输，huffman编码按字符出现概率分配码长，是一种能够使平均码长最短的编码方式
* 第三，支持动态的添加Header，例如第一次请求时传入了'user-agent: Mozilla/5.0'，添加到动态Header表后，后面的请求只需要传数字'62'即可替代原来的header了  
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/fba19bf1daafba4b0d074039c135f5f7.png)

&emsp;&emsp;通过HPACK压缩技术，能够极大的降低请求头在所传输的信息中的占比，提升网络传输效率

#### 多路复用
在HTTP/1.X中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个TCP连接，Chrome支持同一时间最多发送6个请求，这种模型也可能会导致队首阻塞，从而造成底层TCP连接的效率低下

&emsp;&emsp;HTTP/2.0为了解决这个问题，提出了流的概念，每一次请求对应一个流，每个流有一个唯一ID，用来区分不同的请求。基于流的概念，进一步提出了帧，一个请求的数据会被分成多个帧，方便进行数据分割传输，每个帧都唯一属于某一个流ID，将帧按照流ID进行分组，即可分离出不同的请求。这样同一个TCP连接中就可以同时并发传输多个请求。通过这种复用TCP连接的方式，不用再同时建多个连接，提升了TCP的利用效率

&emsp;&emsp;下图中显示客户端正在向服务器传输一个DATA帧（数据流5），与此同时，服务器正向客户端交错发送数据流1和数据流3的一系列帧。因此，下图一个连接上同时有三个并行传输的数据流。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/0b7af2c355f44dadde13a711c04141ad.png)

&emsp;&emsp;将HTTP消息分解为独立的帧，交错发送，然后在另一端重新组装，带来了巨大的性能提升，是HTTP/2.0最重要的一项增强。

#### 数据优先级
将HTTP消息分解为很多独立的帧在同一个流中交错传输后，传输这些帧的顺序就成为决定性能的关键因素。为了做到这一点，HTTP/2.0允许每个数据流都有一个关联的权重和依赖关系。我们可以向每个数据流分配一个介于1至256之间的整数。每个数据流与其他数据流之间也可以存在显式依赖关系。这种数据流依赖关系和权重的组合让客户端可以构建和传递“优先级树”，表明它倾向于如何接收响应。优先级树表示，应尽可能先向父数据流分配资源，然后再向其依赖项分配资源。这样服务器，可以使用此信息通过控制CPU、内存和其他资源的分配设定数据流处理的优先级，确保将高优先级响应以最优方式传输至客户端。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/efb93d8ab7e77a23da1ccebeb12b195a.png)

#### HTTP/2.0实际效果
这个[链接](http://www.http2demo.io/)可以测试同时传输200张小图片时，HTTP/1.1和HTTP/2.0各自的表现，基本相差3倍以上 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/0c180c0a938c436a72d011e3159676a6.png)

### 总结
gPRC使用ProtocolBuffer压缩消息，使用HTTP/2.0协议进行传输，拥有体积小，传输快，支持高并发的特性 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/9cea65bf8eaf8e03c9ed55668df1e3a0.png)

## gRPC进阶使用
### 通信模式
第一小节里面介绍了如何开发一个简易的grpc程序，在示例代码里，客户端每次发送一个请求都能得到客户端的一个响应，这种通信模式简称为一元模式，但是借助grpc可以实现其他的通信模式。

&emsp;&emsp;例如服务器端流模式，能让客户端的一次请求可以得到多次响应，在订单搜索场景使用能提升结果返回的速度。客户端流模式，能把客户端的多次请求聚合起来返回一次响应，在例如订单更新的场景使用能进行批量更新。还有双向流，客户端发送多次请求，服务端返回多次响应，使用场景如可以把很多订单进行分批处理。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/d7d9d3969de69e5ad9100cee019b86a8.png)

&emsp;&emsp;流模式使用也很简单，下面是服务器端流模式的使用示例
protobuffer定义
```
service OrderManagement {
    rpc searchOrders(google.protobuf.StringValue) returns (stream Order);
}

```
client端代码
```
Iterator<Order> matchingOrdersItr = stub.searchOrders(searchStr);
while (matchingOrdersItr.hasNext()) {
    Order matchingOrder = matchingOrdersItr.next();
}
```
server端代码
```
for (int index = 0; index < itemsCount; index++) {
    responseObserver.onNext(order);
}
responseObserver.onCompleted();
```

&emsp;&emsp;在服务器端流模式中，服务端会返回多次消息，发送完后在最后带上一个tailer标识。
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/72b78b5366007c190db6bcd1ef94eafc.png)

### 超时时间与截止时间
在分布式系统调用中，超时时间(Timeout)和截止时间(Deadline)是两个比较常用的模式，我们给下游设置超时时间，只能限制我们的直接下游至少在多少时间内返回，超时时间不能作用于整个调用链路。从而造成资源浪费，而截至时间可以作用于整个下游链路，当请求已经超时时，停止继续处理，及时止损  
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/d834533b4282b861aed72ebec7156e1d.png)
```
resp = GrpcClient.create(MyRpcConfig.myMockService)
      .method(MyFutureClient::doMyAction)
      .withDeadlineAfter(1, TimeUnit.SECONDS)
      .call(...)
      .timeout(1, SECONDS);
```
### gRPC-gateway
gRPC是契约驱动的，服务端和浏览器之间是没有契约的，因此浏览器上是无法直接调用gRPC服务的，为了解决这个问题，grpc官方提供了grpc-gateway插件，grpc-gateway本质是一个protoc插件，我们在编写gRPC服务定义proto文件，通过指定一些自定义选项，在编译时，在生成gRPC代码时，额外指定生成grpc-gateway反向代理相关代码，其作用是生成一个restful api,把 JSON API请求转换为gRPC请求。 
![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/ea8b60b8cb96d7b840959d18cff247c6.png)
kess平台通过反射实现同样的功能，能够让我们在浏览器上方便的进行在线调试gRPC服务

### 拦截器
当客户端发起RPC请求时，借助拦截器，我们可以拦截一元RPC和流式RPC，实现一些特定的可重用的功能例如日志，身份认证，性能埋点等等
更多功能参考gRPC官网和kess官方文档

### 与Thrift简要对比

![null](https://static.yximgs.com/udata/pkg/EE-KSTACK/3d87783ad4abe3f561f998b56b662289.png)
原生gRPC处理性能比Thrift略查一点，但kRPC经过一定优化，性能已经有很大的提升，期待官方数据。

## 总结
既然HTTP/2.0已经把HTTP/1.0的问题都解决了，还引入很多新的特性，那看来的确没必要再更换TCP协议了，另外HTTP2.0将来很可能会成为行业标准，在物联网时代大放异彩，使用标准的应用层协议比自己再撸一个新的协议更容易推广，可能是为什么gRPC没有直接用TCP协议的原因之一吧。当然这只是个人的猜测，很多事后能解释的通的问题，事前谁也无法预测。



参考资料
----
 
 [gRPC与云原生应用开发](https://book.douban.com/subject/35309194/)  
 [gRPC官网](https://grpc.io/blog/coreos/)  
 [HTTP/2 简介](https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-CN)  
 [怎么看待谷歌的开源 RPC 框架 gRPC？](https://www.zhihu.com/question/30027669)  
 [分布式RPC框架性能对比](https://developer.aliyun.com/article/342003)  

